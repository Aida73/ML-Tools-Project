{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iAvwMrsMJtj",
        "outputId": "5dbfe3c5-bcad-44db-c4d0-24b4c1c7dd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/Cours-DIC3/ML&DL Tools/project/models'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJauBdhgMPT4",
        "outputId": "8a668fd7-48e8-4834-f1ca-df186873805a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Cours-DIC3/ML&DL Tools/project/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama_index langchain transformers sentence_transformers"
      ],
      "metadata": {
        "id": "bv-_VpzkljgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "e4xVGkLSDjcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader, LangchainEmbedding, PromptHelper, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper, StorageContext\n",
        "import torch\n",
        "from langchain import OpenAI\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.llms.base import LLM\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "GKxyHsDilxxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract data"
      ],
      "metadata": {
        "id": "EfDByZGhrPJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import extract_data"
      ],
      "metadata": {
        "id": "-98fNtxErObm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_data.extract_data()"
      ],
      "metadata": {
        "id": "w7j21AN2rXaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class CustomLLM(LLM):\n",
        "    model_name = \"Sahajtomar/french_semantic\"\n",
        "    my_model = SentenceTransformer(model_name)\n",
        "\n",
        "    def _call(self, prompt, stop=None):\n",
        "        generated_text = self.my_model(prompt)\n",
        "        return generated_text\n",
        "\n",
        "    def _identifying_params(self):\n",
        "        return {\"name_of_model\": self.model_name}\n",
        "\n",
        "    def _llm_type(self):\n",
        "        return \"custom\"\n",
        "\n",
        "llm_predictor = LLMPredictor(llm=CustomLLM())"
      ],
      "metadata": {
        "id": "8R_mT_9YPhve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfemb = HuggingFaceEmbeddings()\n",
        "embed_model = LangchainEmbedding(hfemb)"
      ],
      "metadata": {
        "id": "kgXIZJVdRCBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader('knowledge').load_data()"
      ],
      "metadata": {
        "id": "5y_KtOE3TD_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_output=1024\n",
        "max_input_size=512\n",
        "max_chunk_overlap=.20\n",
        "\n",
        "prompt_helper = PromptHelper(max_input_size, num_output,max_chunk_overlap)"
      ],
      "metadata": {
        "id": "5_B2KVNvUP1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = GPTListIndex(documents, embed_model=embed_model, llm_predictor=llm_predictor,prompt_helper=prompt_helper)"
      ],
      "metadata": {
        "id": "ron3g8rgUzwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.as_query_engine().query(\"Quand l'ecole polytechnique de Thies a t-elle était créée?\")"
      ],
      "metadata": {
        "id": "1iIC_hd7VNcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.response"
      ],
      "metadata": {
        "id": "3-mzp8i7V2or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = index.as_query_engine().query(\"Quel est le nom complet du directeur de l'EPT?\")"
      ],
      "metadata": {
        "id": "avkw2Q9MKr-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2.response"
      ],
      "metadata": {
        "id": "_AawXdqWKr6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persist index to disk\n",
        "index.storage_context.persist(\"ept_index\")"
      ],
      "metadata": {
        "id": "lZNZlYJFZfAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "# Rebuild storage context\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"ept_index\")\n",
        "\n",
        "# Load index from the storage context\n",
        "new_index = load_index_from_storage(storage_context)\n",
        "\n",
        "new_query_engine = new_index.as_query_engine()\n",
        "my_response = new_query_engine.query(\"who is this text about?\")\n",
        "print(my_response)"
      ],
      "metadata": {
        "id": "-Nlij5oihGuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OgxDXEqsqYWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}